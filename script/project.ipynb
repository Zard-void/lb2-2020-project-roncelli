{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('/home/stefano/PycharmProjects/lb2-2020-project-roncelli/')\n",
    "#jpred = pd.read_csv('./data/jpred4.tsv', sep='\\t')\n",
    "#jpred\n",
    "\n",
    "#sns.boxplot(data=jpred, y= 'SCOPClass', x = 'Length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dssp = {'E': 0,\n",
    "        'H': 0,\n",
    "        '-': 0}\n",
    "\n",
    "for filename in os.listdir('./data/dssp/'):\n",
    "    file = open('./data/dssp/' + filename, 'r')\n",
    "    file.readline()\n",
    "    for line in file:\n",
    "        dssp['H'] += line.count('H')\n",
    "        dssp['E'] += line.count('E')\n",
    "        dssp['-'] += line.count('-')\n",
    "\n",
    "#plt.bar(dssp.keys(), dssp.values())\n",
    "plt.pie(dssp.values(), labels=dssp.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Comparative amino-acid composition of [countplot normalized]:\n",
    "# The entire dataset\n",
    "# The fraction of helix, strand and coil residue\n",
    "\n",
    "amino = {}\n",
    "for filename in os.listdir('./data/fasta/'):\n",
    "    file = open('./data/fasta/' + filename, 'r')\n",
    "    file.readline()\n",
    "    for line in file:\n",
    "        for aa in line.rstrip():\n",
    "            if aa not in amino:\n",
    "                amino[aa] = 1\n",
    "            else:\n",
    "                amino[aa] += 1\n",
    "\n",
    "amino = pd.DataFrame.from_dict(amino, orient='index', columns = ['Counts'])\n",
    "\n",
    "sns.set()\n",
    "amino.reset_index(inplace= True)\n",
    "sns.barplot(data = amino.sort_values('Counts'), x = 'index', y = 'Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "helix = {}\n",
    "strand = {}\n",
    "coil = {}\n",
    "\n",
    "for filename in jpred['DomainID']:\n",
    "    dssp_file = open('./data/dssp/' + filename + '.dssp', 'r')\n",
    "    fasta_file = open('./data/fasta/' + filename + '.fasta', 'r')\n",
    "    dssp_file.readline(), fasta_file.readline()\n",
    "    for dssp_line, fasta_line in zip(dssp_file, fasta_file):\n",
    "        for secondary, aa in zip(dssp_line.rstrip(), fasta_line.rstrip()):\n",
    "            if secondary == 'H':\n",
    "                helix[aa] = helix.get(aa, 0) + 1\n",
    "            elif secondary == 'E':\n",
    "                strand[aa] = strand.get(aa, 0) + 1\n",
    "            else:\n",
    "                coil[aa] = coil.get(aa, 0) + 1\n",
    "    dssp_file.close(), fasta_file.close()\n",
    "    \n",
    "coil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "secondary_structure = []\n",
    "amino = []\n",
    "count = []\n",
    "\n",
    "for filename in jpred['DomainID']:\n",
    "    dssp_file = open('./data/dssp/' + filename + '.dssp', 'r')\n",
    "    fasta_file = open('./data/fasta/' + filename + '.fasta', 'r')\n",
    "    dssp_file.readline(), fasta_file.readline()\n",
    "    for dssp_line, fasta_line in zip(dssp_file, fasta_file):\n",
    "        for (secondary, aa) in zip(dssp_line, fasta_line):\n",
    "            #print(secondary, aa)\n",
    "            if secondary in secondary_structure and aa in amino:\n",
    "                if secondary_structure.index(secondary) == amino.index(aa): \n",
    "                    \n",
    "                    count[secondary_structure.index(secondary)] +=1\n",
    "            else:\n",
    "                secondary_structure.append(secondary)\n",
    "                amino.append(aa)\n",
    "                count.append(0)\n",
    "                    \n",
    "    dssp_file.close(), fasta_file.close()\n",
    "\n",
    "people = {\"Structure\": secondary_structure, \"Aminoacid\": amino, \"Count\": count}\n",
    "people\n",
    "#composition1 = pd.DataFrame(people) \n",
    "#composition1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "composition = pd.DataFrame([helix, strand, coil], index = ['Helix', 'Strand', 'Coil']).T\n",
    "\n",
    "composition = composition.melt(ignore_index = False, value_name = 'Count', var_name = 'Structure')\n",
    "composition.reset_index(level=0, inplace=True)\n",
    "composition = composition[composition['index'] != '\\n']\n",
    "composition\n",
    "plt.figure(figsize=(15,4))\n",
    "sns.barplot(data=composition, hue='Structure', x='index', y='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Taxonomic classification (at superkingdom [pie] and species level [pie or countplot,\n",
    "# reducing the number of species to top 5/10/20])\n",
    "\n",
    "jpred.Suprekingdom.value_counts().plot.pie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Top x specie\n",
    "jpred.TaxaName.value_counts()[0:10].plot.pie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Structural classification (SCOP class)\n",
    "\n",
    "jpred.SCOPClass.value_counts().plot.pie(autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin project code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import the csv\n",
    "import os\n",
    "import pandas as pd\n",
    "os.chdir('/home/stefano/PycharmProjects/lb2-2020-project-roncelli/data/test/')\n",
    "test = pd.read_csv('test.csv', usecols=[0,1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reduce internal redundancy\n",
    "\n",
    "def reduce_internal_redundancy():\n",
    "    test = test[test['Sequence'].str.contains('X') == False]\n",
    "    test['Chain Length'] = pd.to_numeric(test['Chain Length'] , errors='coerce')\n",
    "    test = test[test['Chain Length'].isna() == False]\n",
    "    test = test.reset_index(drop = True)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Extract unclustered sequences to file\n",
    "\n",
    "from os import path\n",
    "if path.exists('test_unclustered.fasta'):\n",
    "    os.remove('test_unclustered.fasta')\n",
    "test_unclustered = open('test_unclustered.fasta', 'a')\n",
    "for index in test.index:\n",
    "        sequence = test.loc[index, 'Sequence']\n",
    "        id = test.loc[index, 'PDB ID']\n",
    "        chain = test.loc[index, 'Chain ID'].split(',')[0]\n",
    "        print('>', id,'_', chain, '\\n', sequence, sep='', end='\\n', file = test_unclustered)\n",
    "test_unclustered.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Run the clustering\n",
    "\n",
    "%cd ~/PycharmProjects/lb2-2020-project-roncelli/data/test/\n",
    "!mmseqs createdb test_unclustered.fasta db/testDB\n",
    "!mmseqs cluster db/testDB test.clstr tmp/ --min-seq-id 0.3 -c 0.5 --cov-mode 0\n",
    "!mmseqs createsubdb test.clstr db/testDB representatives\n",
    "!mmseqs convert2fasta representatives representatives.fasta\n",
    "!rm -r tmp/*\n",
    "!rm test_unclustered.fasta \n",
    "!clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Identify the sequences in the test set similar to the training\n",
    "\n",
    "!blastp -query representatives.fasta -out representatives_similar.tsv -db db/jpred.fasta -outfmt 6 -evalue 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "\n",
    "to_keep = ['test.csv', 'representatives_similar.tsv', 'representatives.fasta']\n",
    "for file in os.listdir('.'):\n",
    "    if os.path.isfile(file) and file not in to_keep:\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read the similar representatives from the blast output\n",
    "\n",
    "representatives_similar = pd.read_csv('representatives_similar.tsv', \n",
    "                                      sep='\\t',\n",
    "                                      names=['Query', \n",
    "                                             'Subject', \n",
    "                                             'Identity', \n",
    "                                             'Length', \n",
    "                                             'mismatches', \n",
    "                                             'gap opens', \n",
    "                                             'Query start', \n",
    "                                             'Quesry end', \n",
    "                                             'Sequence start', \n",
    "                                             'Sequence end',\n",
    "                                             'E-value', \n",
    "                                             'Bit score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the representatives dataframe\n",
    "\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "\n",
    "os.chdir('/home/stefano/PycharmProjects/lb2-2020-project-roncelli/data/test')\n",
    "\n",
    "representatives = list()\n",
    "for record in SeqIO.parse(\"representatives.fasta\", \"fasta\"):\n",
    "    representatives.append([record.id, str(record.seq)])\n",
    "\n",
    "representatives = pd.DataFrame(representatives, columns=['ID', 'Sequence'])    \n",
    "similar_id = representatives_similar[representatives_similar['Identity'] > 30]\n",
    "similar_id = similar_id['Query'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Take a random sample\n",
    "\n",
    "import random\n",
    "test_list = random.sample(representatives['ID'].to_list(), k = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Custom function to extract chains from a cif file \n",
    "\n",
    "import os\n",
    "def extract_chain(file_path, out_path, chain):\n",
    "    base_name = os.path.basename(file_path)\n",
    "    name = os.path.splitext(base_name)[0]\n",
    "    extension = '.cif'\n",
    "    file = open(file_path + extension)\n",
    "    if os.path.exists(out_path + name + '_' + chain + extension):\n",
    "        os.remove(out_path + name + '_' + chain + extension)\n",
    "    out = open(out_path + name + '_' + chain + extension, 'a')\n",
    "    print(file.readline().rstrip() + '_' + chain + '\\n#' + '\\nloop_', end = '\\n', file = out)\n",
    "    counter = 0\n",
    "    chain_index = 0\n",
    "    for line in file:\n",
    "        if line.startswith('_atom_site.'):\n",
    "            while line.startswith('_atom_site.'):\n",
    "                if 'auth_asym_id' in line:\n",
    "                    chain_index = counter\n",
    "                print(line, end = '', file = out)\n",
    "                line = file.readline()\n",
    "                counter += 1\n",
    "        line2 = line.split()\n",
    "        if len(line2) >= chain_index + 1 and line2[0] == 'ATOM' and line2[chain_index] == chain:\n",
    "            print(line, end = '', file = out)\n",
    "    print('#', file = out)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Download the structure file and extract the chains\n",
    "\n",
    "from Bio.PDB import PDBIO\n",
    "from Bio.PDB import FastMMCIFParser\n",
    "from Bio.PDB import PDBList\n",
    "from tqdm.notebook import tqdm\n",
    "os.chdir('/home/stefano/PycharmProjects/lb2-2020-project-roncelli/data/test/pdb')\n",
    "\n",
    "pdbl = PDBList()\n",
    "for record in tqdm(test_list):\n",
    "    id = record[:4]\n",
    "    chain = record[5:]\n",
    "    #pdbl.retrieve_pdb_file(id, pdir = '.', file_format='mmCif')\n",
    "    #os.rename(id.lower() + '.cif', id + '.cif')\n",
    "    extract_chain(id.lower(), 'singlechains/', chain)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for filename in os.listdir('.'):\n",
    "    os.rename(filename, filename.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Custom function to remap secondary structures to simplified alphabet (C-H-E)\n",
    "\n",
    "def ss_mapper(structure): \n",
    "    mapped_structure = []\n",
    "    position = int()\n",
    "    for secondary in structure:\n",
    "        if secondary == ' ' or secondary == 'T' or secondary == 'S' or secondary == '-':\n",
    "             secondary = 'C'\n",
    "        elif secondary == 'H' or secondary == 'G' or secondary == 'I':\n",
    "            secondary = 'H'\n",
    "        elif secondary == 'B' or secondary == 'E':            \n",
    "            secondary = 'E'\n",
    "        else:\n",
    "            if secondary == '\\n':\n",
    "                raise Exception('Character is a newline. Did you remember to rstrip?')\n",
    "            else:\n",
    "                raise Exception('Aminoacid in position ' + str(position) + ' is ' + \"'\" + secondary + \"'\")\n",
    "        position += 1\n",
    "        mapped_structure.append(secondary)\n",
    "    mapped_structure = ''.join([str(elem) for elem in mapped_structure]) \n",
    "    return mapped_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the DSSP dataframe with Biopython\n",
    "\n",
    "import pandas as pd\n",
    "from Bio.PDB.MMCIFParser import MMCIFParser\n",
    "from Bio.PDB.DSSP import dssp_dict_from_pdb_file\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "dssp_df = pd.DataFrame(columns=['PDB ID', \"Sequence\", \"Secondary structure\"])\n",
    "os.chdir('/home/stefano/PycharmProjects/lb2-2020-project-roncelli/data/test/pdb/singlechains/')\n",
    "parser = MMCIFParser()\n",
    "\n",
    "for pdb_id in tqdm(test_list):\n",
    "    sequence = ''\n",
    "    structure = ''\n",
    "\n",
    "    structure = parser.get_structure(pdb_id, pdb_id.lower() + '.cif')\n",
    "    dssp_dict = dssp_dict_from_pdb_file(pdb_id.lower() + '.cif')[0]\n",
    "    entry_df = pd.DataFrame(dssp_dict).T\n",
    "    entry_df.reset_index(drop = True)\n",
    "\n",
    "    sequence = entry_df[0].str.cat()\n",
    "    structure = ss_mapper(entry_df[1].str.cat())\n",
    "    dssp_df = dssp_df.append({'PDB ID': pdb_id,\n",
    "                   'Sequence': sequence,\n",
    "                   'Secondary structure': structure}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Run DSSP with shell\n",
    "\n",
    "import os\n",
    "os.chdir('/home/stefano/PycharmProjects/lb2-2020-project-roncelli/data/test/pdb/singlechains/')\n",
    "\n",
    "for pdb_id in tqdm(test_list):\n",
    "    stream = os.popen('dssp -i ' + pdb_id.lower() + '.cif' + ' -o ../../dssp/' + pdb_id + '.dssp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create DSSP dataframe from output file created with Bash\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "os.chdir('/home/stefano/PycharmProjects/lb2-2020-project-roncelli/data/test/dssp')\n",
    "\n",
    "dssp_df = pd.DataFrame(columns=['PDB ID', \"Sequence\", \"Secondary structure\"])\n",
    "for pdb_id in test_list:\n",
    "    if pdb_id + '.dssp' in os.listdir('.'):\n",
    "        with open(pdb_id + '.dssp') as handle:\n",
    "            sequence = list()\n",
    "            structure = list()\n",
    "            line = handle.readline().split()\n",
    "            while line[0] != '#':\n",
    "                line = handle.readline().split()\n",
    "            for line in handle:\n",
    "                line = list(line)\n",
    "                if line[13] == '!':\n",
    "                    sequence.append('X')\n",
    "                    structure.append(' ')\n",
    "                else:\n",
    "                    sequence.append(line[13])\n",
    "                    structure.append(line[16])\n",
    "        sequence = ''.join(sequence)\n",
    "        structure = ''.join(structure)\n",
    "        structure = ss_mapper(structure)\n",
    "        dssp_df = dssp_df.append({'PDB ID': pdb_id,\n",
    "                                  'Sequence': sequence,\n",
    "                                  'Secondary structure': structure}, ignore_index = True)\n",
    "dssp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a = ['5AJS_A', '4WA6_B']\n",
    "dssp_df.query(\"Sequence in @test.Sequence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dssp_df[dssp_df['Sequence'] == 'RKCPSPNVIIITKPWEKGLKAITVAIRRNAIDSLPPNIKSLNYLNNILAKIEANAKGGDEAIFLDHNGYISEGSGDNIFIVKNGTITTPPTLNNLKGITRQVVIELINELEIPFREANIGLFDLYSADEIFVTGTAAEIAPVTYIDGRTVGNGKPGKVTKMLMEKFRERTENEGVEIYR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "representatives[representatives['ID'] == '5CM0_A'].Sequence.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for sequence in dssp_df.Sequence:\n",
    "    len_dssp = int()\n",
    "    len_test = int()\n",
    "    sequence = sequence.replace('X', '')\n",
    "    match = test.Sequence.str.match(sequence).any()\n",
    "    if not match:\n",
    "        truncated_sequence = representatives[representatives.Sequence.str.contains(sequence)]\n",
    "    \n",
    "        print(sequence)\n",
    "        print(truncated_sequence)\n",
    "        truncated_sequence = truncated_sequence.iloc[0]\n",
    "        #print(sequence)\n",
    "        #print(truncated_sequence['Sequence'], sep = '\\n')\n",
    "     #   found = test.loc[test['Sequence'].str.contains(sequence)]\n",
    "        \n",
    "      #  print(found.iloc[0, 2].find(sequence))\n",
    "        #print(len(sequence), ' ', len(found['Sequence'].values[0]))\n",
    "   # else:\n",
    "        #print(sequence, 'OK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for index1 in test.index:\n",
    "    for index in dssp_df.index:\n",
    "        if dssp_df.loc[index,\"PDB ID\"].split(\"_\")[0]==test.loc[index1,\"PDB ID\"]:\n",
    "            if dssp_df.loc[index,\"PDB ID\"].split(\"_\")[1]==test.loc[index1,\"Chain ID\"].split(\",\")[0]:\n",
    "                print(test.loc[index1,\"PDB ID\"])\n",
    "                print(\"dssp\")\n",
    "                print(dssp_df.loc[index,\"Sequence\"])\n",
    "                print(\"fasta\")\n",
    "                print(test.loc[index1,\"Sequence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Run PSI blast\n",
    "\n",
    "import os   \n",
    "from Bio.Blast.Applications import NcbipsiblastCommandline\n",
    "from tqdm.notebook import tqdm\n",
    "for fasta_file in tqdm(os.listdir('training/fasta/')):\n",
    "    break # to not run everything\n",
    "    base_name = os.path.basename(fasta_file)\n",
    "    name = os.path.splitext(base_name)[0]\n",
    "    cmd = NcbipsiblastCommandline(query = 'training/fasta/' + base_name, \n",
    "                                  db = 'swiss-prot/uniprot_sprot.fasta', \n",
    "                                  evalue = 0.01,\n",
    "                                  num_iterations = 3, \n",
    "                                  out_ascii_pssm = 'psiblast_output/' + name + '.pssm', \n",
    "                                  num_descriptions = 10000,\n",
    "                                  num_alignments = 10000, \n",
    "                                  out= 'psiblast_output/' + name + '.alns.blast', \n",
    "                                  num_threads = 8)\n",
    "\n",
    "    cmd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f6be1ae9074052a844e6bb2706dc9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Parsing', max=1252.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the profile files\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from script.ss_mapper import ss_mapper\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "os.chdir('/home/stefano/PycharmProjects/lb2-2020-project-roncelli/data/training/')\n",
    "for sample in tqdm(os.listdir('pssm'), desc='Parsing'):\n",
    "    time.sleep(0.01)\n",
    "    base_name = os.path.basename(sample)\n",
    "    name = os.path.splitext(base_name)[0]\n",
    "    with open('pssm/' + sample, 'r') as pssm_file, open('dssp/' + name + '.dssp') as dssp_file:\n",
    "            dssp_file.readline()\n",
    "            structure = dssp_file.readline().rstrip()\n",
    "            structure = ' ' + ss_mapper(structure)\n",
    "            pssm_file.readline()\n",
    "            pssm_file.readline()\n",
    "            file_list = []\n",
    "            offset = False\n",
    "            position = 0\n",
    "            for line in pssm_file:\n",
    "                line = line.rstrip()\n",
    "                if not line:\n",
    "                    break\n",
    "                line = line.split()\n",
    "                line.append(structure[position])\n",
    "                position += 1\n",
    "                if not offset:\n",
    "                    for i in range(2):\n",
    "                        line.insert(0, '')\n",
    "                        offset = True\n",
    "                file_list.append(line)\n",
    "            df = pd.DataFrame(file_list)\n",
    "            #df.drop(df.tail(6).index, inplace=True)\n",
    "            df.drop((df.columns[col] for col in range(2,22)), axis=1, inplace=True)\n",
    "            df.drop((df.columns[-3:-1]), axis = 1,inplace = True)\n",
    "            df.drop((df.columns[0]), axis = 1, inplace = True)\n",
    "            df.columns = df.iloc[0] #grab the first row for the header\n",
    "            df = df[1:] #take the data less the header row #set the header row as the df header\n",
    "            df.rename(columns={ df.columns[0]: \"Sequence\" }, inplace = True)\n",
    "            df.rename(columns={ df.columns[-1]: \"Structure\" }, inplace = True)\n",
    "            df = df[ ['Structure'] + [ col for col in df.columns if col != 'Structure' ] ]\n",
    "            df.loc[:, 'A':'V'] = df.loc[:, 'A':'V'].astype(float).divide(100)\n",
    "            df.to_csv('profile/' + name + '.profile',sep='\\t', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Removes profiles that are all zeroes\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "os.chdir('/home/stefano/PycharmProjects/lb2-2020-project-roncelli/data/training/profile')\n",
    "for file in os.listdir():\n",
    "    df = pd.read_csv(file, sep = '\\t')\n",
    "    df = df.iloc[:, 2:]\n",
    "    if not df.any(axis = None):\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Check if structure file has breaks\n",
    "\n",
    "import os\n",
    "os.chdir('/home/stefano/PycharmProjects/lb2-2020-project-roncelli/data/test/pdb/singlechains/')\n",
    "def has_break(file_handle):\n",
    "    base_name = os.path.basename(file_handle)\n",
    "    name = os.path.splitext(base_name)[0]\n",
    "    counter = 0\n",
    "    residue_index = 0\n",
    "    latest_numer = 0\n",
    "    file = open(file_handle)\n",
    "    residue_list = []\n",
    "    for line in file:\n",
    "        if line.startswith('_atom_site.'):\n",
    "             while line.startswith('_atom_site.'):\n",
    "                if 'auth_seq_id' in line:\n",
    "                    residue_index = counter\n",
    "                line = file.readline()\n",
    "                counter += 1\n",
    "        line = line.split()\n",
    "\n",
    "        if len(line) > residue_index and line[0] == 'ATOM':\n",
    "            residue_list.append(line[residue_index])\n",
    "\n",
    "    for i in range(len(residue_list) - 1):\n",
    "        if int(residue_list[i+1]) > int(residue_list[i]) + 1:\n",
    "            break_length = int(residue_list[i +1]) - int(residue_list[i]) - 1\n",
    "            print(base_name, 'Found break! Residues ', residue_list[i], '-', residue_list[i + 1], ' Break length: ', break_length)    \n",
    "\n",
    "for file in os.listdir('.'):\n",
    "    has_break(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
